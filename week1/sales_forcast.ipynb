{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xs7YbkgvohAU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "import xgboost as xgb\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from prophet import Prophet\n",
        "\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcFDUk8YppSd",
        "outputId": "79f42484-7335-4109-c366-8c24ad0db416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 73100 entries, 0 to 73099\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Non-Null Count  Dtype         \n",
            "---  ------              --------------  -----         \n",
            " 0   Date                73100 non-null  datetime64[ns]\n",
            " 1   Store ID            73100 non-null  object        \n",
            " 2   Product ID          73100 non-null  object        \n",
            " 3   Category            73100 non-null  object        \n",
            " 4   Region              73100 non-null  object        \n",
            " 5   Inventory Level     73100 non-null  int64         \n",
            " 6   Units Sold          73100 non-null  int64         \n",
            " 7   Units Ordered       73100 non-null  int64         \n",
            " 8   Demand Forecast     73100 non-null  float64       \n",
            " 9   Price               73100 non-null  float64       \n",
            " 10  Discount            73100 non-null  int64         \n",
            " 11  Weather Condition   73100 non-null  object        \n",
            " 12  Holiday/Promotion   73100 non-null  int64         \n",
            " 13  Competitor Pricing  73100 non-null  float64       \n",
            " 14  Seasonality         73100 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(3), int64(5), object(6)\n",
            "memory usage: 8.4+ MB\n",
            "\n",
            "First 5 Rows:\n",
            "        Date Store ID Product ID     Category Region  Inventory Level  \\\n",
            "0 2022-01-01     S001      P0001    Groceries  North              231   \n",
            "1 2022-01-01     S001      P0002         Toys  South              204   \n",
            "2 2022-01-01     S001      P0003         Toys   West              102   \n",
            "3 2022-01-01     S001      P0004         Toys  North              469   \n",
            "4 2022-01-01     S001      P0005  Electronics   East              166   \n",
            "\n",
            "   Units Sold  Units Ordered  Demand Forecast  Price  Discount  \\\n",
            "0         127             55           135.47  33.50        20   \n",
            "1         150             66           144.04  63.01        20   \n",
            "2          65             51            74.02  27.99        10   \n",
            "3          61            164            62.18  32.72        10   \n",
            "4          14            135             9.26  73.64         0   \n",
            "\n",
            "  Weather Condition  Holiday/Promotion  Competitor Pricing Seasonality  \n",
            "0             Rainy                  0               29.69      Autumn  \n",
            "1             Sunny                  0               66.16      Autumn  \n",
            "2             Sunny                  1               31.32      Summer  \n",
            "3            Cloudy                  1               34.74      Autumn  \n",
            "4             Sunny                  0               68.95      Summer  \n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "file_name = \"retail_store_inventory.csv\"\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# ➡️ Convert the date column to datetime objects\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# ➡️ The target variable for forecasting is 'Units Sold'\n",
        "TARGET_COLUMN = 'Units Sold'\n",
        "\n",
        "print(\"Data Info:\")\n",
        "df.info()\n",
        "print(\"\\nFirst 5 Rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moDdoBiFpxws",
        "outputId": "f2f2ab3a-202b-4c3f-d771-7948a1eb76b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregated Daily Data Head:\n",
            "| Date                | Units Sold   | Price   | Discount   | Competitor Pricing   | Demand Forecast   | Weather Condition   | Holiday/Promotion   |\n",
            "|:--------------------|:-------------|:--------|:-----------|:---------------------|:------------------|:--------------------|:--------------------|\n",
            "| 2022-01-01 00:00:00 | 14484        | 57.5157 | 10.65      | 58.1831              | 150.313           | Cloudy              | 1                   |\n",
            "| 2022-01-02 00:00:00 | 13415        | 60.6365 | 9.8        | 60.2371              | 139.107           | Cloudy              | 0                   |\n",
            "| 2022-01-03 00:00:00 | 13681        | 56.7993 | 8.85       | 56.8813              | 141.853           | Cloudy              | 0                   |\n",
            "| 2022-01-04 00:00:00 | 14084        | 52.993  | 10.6       | 52.8153              | 146.091           | Sunny               | 1                   |\n",
            "| 2022-01-05 00:00:00 | 12572        | 55.9958 | 10.4       | 56.0426              | 130.917           | Rainy               | 0                   |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3987031774.py:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_agg.fillna(method='ffill', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# 1. Aggregate to Total Daily Sales\n",
        "# We sum the 'Units Sold' across all stores and products for each day.\n",
        "daily_sales = df.groupby('Date')[TARGET_COLUMN].sum().to_frame()\n",
        "\n",
        "# 2. Prepare Exogenous Features (Daily Averages/Maximums)\n",
        "# We aggregate the external features to the daily level, taking the mean or mode.\n",
        "\n",
        "# Numerical Features (use mean)\n",
        "exog_numerical = df.groupby('Date')[['Price', 'Discount', 'Competitor Pricing', 'Demand Forecast']].mean()\n",
        "\n",
        "# Categorical Features (use mode - most frequent)\n",
        "exog_categorical = df.groupby('Date')[['Weather Condition', 'Holiday/Promotion']].agg(lambda x: x.mode()[0])\n",
        "\n",
        "# Combine all features\n",
        "df_agg = daily_sales.join([exog_numerical, exog_categorical])\n",
        "df_agg.index.name = 'Date' # Rename index for clarity\n",
        "\n",
        "# ⚠️ Handle Missing Values (Check if any NaN resulted from aggregation)\n",
        "# For this dataset, we expect very few, if any, NaN values after daily aggregation.\n",
        "df_agg.fillna(method='ffill', inplace=True)\n",
        "\n",
        "print(\"Aggregated Daily Data Head:\")\n",
        "print(df_agg.head().to_markdown(numalign=\"left\", stralign=\"left\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9BIXm-7qGHe",
        "outputId": "47301090-524c-4f8e-a7c0-e2781a8f0c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Features Created:\n",
            "| Date                | Units Sold   | Price   | Discount   | Competitor Pricing   | Demand Forecast   | Holiday/Promotion   | dayofweek   | dayofyear   | weekofyear   | month   | year   | lag_1   | lag_7   | lag_30   | rolling_mean_7   | Weather Condition_Rainy   | Weather Condition_Snowy   | Weather Condition_Sunny   |\n",
            "|:--------------------|:-------------|:--------|:-----------|:---------------------|:------------------|:--------------------|:------------|:------------|:-------------|:--------|:-------|:--------|:--------|:---------|:-----------------|:--------------------------|:--------------------------|:--------------------------|\n",
            "| 2022-01-31 00:00:00 | 13187        | 55.2553 | 9.45       | 55.0981              | 136.82            | 1                   | 0           | 31          | 5            | 1       | 2022   | 13994   | 11277   | 14484    | 13284            | True                      | False                     | False                     |\n",
            "| 2022-02-01 00:00:00 | 13852        | 52.2507 | 10.7       | 52.357               | 143.577           | 1                   | 1           | 32          | 5            | 2       | 2022   | 13187   | 13945   | 13415    | 13556.9          | False                     | False                     | False                     |\n",
            "| 2022-02-02 00:00:00 | 14547        | 52.2146 | 9.6        | 52.465               | 149.698           | 1                   | 2           | 33          | 5            | 2       | 2022   | 13852   | 13680   | 13681    | 13543.6          | False                     | False                     | False                     |\n",
            "| 2022-02-03 00:00:00 | 12774        | 54.1838 | 10.1       | 53.7434              | 132.472           | 1                   | 3           | 34          | 5            | 2       | 2022   | 14547   | 13761   | 14084    | 13667.4          | False                     | False                     | True                      |\n",
            "| 2022-02-04 00:00:00 | 12904        | 54.5477 | 9.8        | 54.8315              | 134.398           | 1                   | 4           | 35          | 5            | 2       | 2022   | 12774   | 13162   | 12572    | 13526.4          | False                     | True                      | False                     |\n"
          ]
        }
      ],
      "source": [
        "def create_time_series_features(data):\n",
        "    # 1. Date Features\n",
        "    data['dayofweek'] = data.index.dayofweek\n",
        "    data['dayofyear'] = data.index.dayofyear\n",
        "    data['weekofyear'] = data.index.isocalendar().week.astype(int)\n",
        "    data['month'] = data.index.month\n",
        "    data['year'] = data.index.year\n",
        "\n",
        "    # 2. Lag Features (Target Variable Lags)\n",
        "    # Sales from 1, 7, and 30 days ago\n",
        "    data['lag_1'] = data[TARGET_COLUMN].shift(1)\n",
        "    data['lag_7'] = data[TARGET_COLUMN].shift(7)\n",
        "    data['lag_30'] = data[TARGET_COLUMN].shift(30)\n",
        "\n",
        "    # 3. Rolling Window Features (e.g., 7-day rolling mean)\n",
        "    data['rolling_mean_7'] = data[TARGET_COLUMN].shift(1).rolling(window=7).mean()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply feature creation to the aggregated data\n",
        "df_feat = create_time_series_features(df_agg.copy())\n",
        "\n",
        "# 4. Handle Categorical Exogenous Variables (One-Hot Encoding for XGBoost)\n",
        "df_feat = pd.get_dummies(df_feat, columns=['Weather Condition'], drop_first=True)\n",
        "\n",
        "# Drop rows with NaN values resulting from lags/rolling windows\n",
        "df_feat.dropna(inplace=True)\n",
        "\n",
        "print(\"\\nFeatures Created:\")\n",
        "print(df_feat.head().to_markdown(numalign=\"left\", stralign=\"left\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiGLlK6xqmDJ",
        "outputId": "2f395db0-f922-4833-bb12-1c5b7c1cb187"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2416941750.py:50: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_agg.fillna(method='ffill', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training Random Forest (Best Model) ---\n",
            "Random Forest (Validation): RMSE=88.34, MAPE=0.53%\n",
            "\n",
            "--- Training SARIMAX (Baseline) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SARIMAX (Validation): RMSE=1233.45, MAPE=7.29%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "import os\n",
        "import matplotlib.pyplot as plt # Used for SARIMAX diagnostic plotting\n",
        "\n",
        "# --- Configuration ---\n",
        "file_name = \"retail_store_inventory.csv\"\n",
        "TARGET_COLUMN = 'Units Sold'\n",
        "TEST_SIZE = 30 # Number of days to use for validation/testing\n",
        "\n",
        "# --- Helper Functions (KPIs & Feature Engineering) ---\n",
        "\n",
        "def create_time_series_features(data):\n",
        "    # This must match the features used in the training data exactly\n",
        "    data['dayofweek'] = data.index.dayofweek\n",
        "    data['dayofyear'] = data.index.dayofyear\n",
        "    data['weekofyear'] = data.index.isocalendar().week.astype(int)\n",
        "    data['month'] = data.index.month\n",
        "    data['year'] = data.index.year\n",
        "    data['lag_1'] = data[TARGET_COLUMN].shift(1)\n",
        "    data['lag_7'] = data[TARGET_COLUMN].shift(7)\n",
        "    data['lag_30'] = data[TARGET_COLUMN].shift(30)\n",
        "    data['rolling_mean_7'] = data[TARGET_COLUMN].shift(1).rolling(window=7).mean()\n",
        "    return data\n",
        "\n",
        "def calculate_kpis(y_true, y_pred, model_name):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    return {'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# --- 1. Day 3: Modeling & Cross-Validation ---\n",
        "\n",
        "# --- Data Preparation (Full Pipeline Re-run) ---\n",
        "\n",
        "# Load and prepare data (same as Day 1/2)\n",
        "df = pd.read_csv(file_name)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Aggregation and Exogenous Features\n",
        "daily_sales = df.groupby('Date')[TARGET_COLUMN].sum().to_frame()\n",
        "exog_numerical = df.groupby('Date')[['Price', 'Discount', 'Competitor Pricing', 'Demand Forecast']].mean()\n",
        "exog_categorical = df.groupby('Date')[['Holiday/Promotion']].agg(lambda x: x.mode()[0])\n",
        "df_agg = daily_sales.join([exog_numerical, exog_categorical])\n",
        "df_agg.index.name = 'Date'\n",
        "df_agg.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Feature Engineering\n",
        "df_feat = create_time_series_features(df_agg.copy())\n",
        "df_feat.dropna(inplace=True)\n",
        "\n",
        "# Data Split\n",
        "train = df_feat.iloc[:-TEST_SIZE]\n",
        "test = df_feat.iloc[-TEST_SIZE:]\n",
        "FEATURES = df_feat.columns.drop(TARGET_COLUMN).tolist()\n",
        "TARGET = TARGET_COLUMN\n",
        "\n",
        "X_train, y_train = train[FEATURES], train[TARGET]\n",
        "X_test, y_test = test[FEATURES], test[TARGET]\n",
        "\n",
        "\n",
        "# --- A. Random Forest (ML Model) ---\n",
        "print(\"--- Training Random Forest (Best Model) ---\")\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "rf_kpis = calculate_kpis(y_test, rf_preds, \"Random Forest\")\n",
        "print(f\"Random Forest (Validation): RMSE={rf_kpis['RMSE']:.2f}, MAPE={rf_kpis['MAPE']:.2f}%\")\n",
        "\n",
        "\n",
        "# --- B. SARIMAX (Statistical Model) ---\n",
        "print(\"\\n--- Training SARIMAX (Baseline) ---\")\n",
        "SARIMAX_train = daily_sales.iloc[:-TEST_SIZE]\n",
        "SARIMAX_test = daily_sales.iloc[-TEST_SIZE:]\n",
        "\n",
        "try:\n",
        "    sarimax_model = SARIMAX(\n",
        "        SARIMAX_train[TARGET_COLUMN],\n",
        "        order=(1, 1, 1),\n",
        "        seasonal_order=(1, 1, 1, 7), # Weekly seasonality S=7\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False\n",
        "    )\n",
        "    sarimax_results = sarimax_model.fit(disp=False)\n",
        "    sarimax_preds = sarimax_results.predict(\n",
        "        start=SARIMAX_test.index[0],\n",
        "        end=SARIMAX_test.index[-1]\n",
        "    )\n",
        "    sarimax_kpis = calculate_kpis(SARIMAX_test[TARGET_COLUMN], sarimax_preds, \"SARIMAX\")\n",
        "    print(f\"SARIMAX (Validation): RMSE={sarimax_kpis['RMSE']:.2f}, MAPE={sarimax_kpis['MAPE']:.2f}%\")\n",
        "\n",
        "    # Combine results\n",
        "    sarimax_preds.index.name = 'Date'\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual Sales': y_test,\n",
        "        'Random Forest Forecast': rf_preds,\n",
        "        'SARIMAX Forecast': sarimax_preds\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(f\"SARIMAX failed to converge: {e}. Only using Random Forest results.\")\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual Sales': y_test,\n",
        "        'Random Forest Forecast': rf_preds\n",
        "    })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQWoEK-xtaPE",
        "outputId": "fe4125ec-a472-43eb-b153-5ac3d8a845e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Day 4: Final Model Training (Deployment) ---\n",
            "Deployment Model Saved: rf_sales_forecast_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Day 4: Model Deployment ---\n",
        "\n",
        "# Train the final Random Forest model on ALL available feature-engineered data\n",
        "print(\"\\n--- Day 4: Final Model Training (Deployment) ---\")\n",
        "\n",
        "X_deploy = df_feat.drop(TARGET_COLUMN, axis=1)\n",
        "y_deploy = df_feat[TARGET_COLUMN]\n",
        "\n",
        "rf_deployment_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_deployment_model.fit(X_deploy, y_deploy)\n",
        "\n",
        "# Export model as pickle\n",
        "pickle_filename = 'rf_sales_forecast_model.pkl'\n",
        "with open(pickle_filename, 'wb') as file:\n",
        "    pickle.dump(rf_deployment_model, file)\n",
        "\n",
        "print(f\"Deployment Model Saved: {pickle_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxGqj_U1tgwf",
        "outputId": "3686c54b-bcfa-4fbc-fe0a-929dd35898e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Day 5: Creating Final Plotly Dashboard ---\n",
            "Dashboard JSON Saved: final_forecast_dashboard.json\n",
            "\n",
            "Final comparison data saved to final_model_comparison_results.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- 3. Day 5: Delivery and Visualization ---\n",
        "\n",
        "# Plotting the combined results\n",
        "print(\"\\n--- Day 5: Creating Final Plotly Dashboard ---\")\n",
        "\n",
        "fig = px.line(results_df, y=results_df.columns,\n",
        "              title='Sales Forecast Comparison: Actuals vs. Models',\n",
        "              labels={'value':'Units Sold', 'Date':'Date'},\n",
        "              line_dash_map={'Actual Sales': 'solid', 'Random Forest Forecast': 'dot', 'SARIMAX Forecast': 'dash'}\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Date',\n",
        "    yaxis_title='Units Sold',\n",
        "    hovermode='x unified',\n",
        "    legend_title='Series'\n",
        ")\n",
        "\n",
        "# Save the visualization\n",
        "plotly_filename = 'final_forecast_dashboard.json'\n",
        "fig.write_json(plotly_filename)\n",
        "print(f\"Dashboard JSON Saved: {plotly_filename}\")\n",
        "\n",
        "# Save the final comparison data for review\n",
        "results_df.to_csv('final_model_comparison_results.csv')\n",
        "print(\"\\nFinal comparison data saved to final_model_comparison_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
